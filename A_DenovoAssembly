#####
# write SBATCH file with nano
#####

# First DEBUG with the debug partition
#!/bin/sh

#SBATCH --time=00:15:00 ## Max time on debug is 15 mn
#SBATCH --cpus-per-task=6
#SBATCH --mem=20G
#SBATCH --partition=shared
#SBATCH --mail-type=ALL


module load GCC/6.3.0-2.27 OpenMPI/2.0.2 Trinity/2.6.6 Salmon/0.9.1-Python-2.7.12 Jellyfish/2.2.6 Bowtie2/2.3.2 SAMtools/1.8

srun Trinity --seqType fq --max_memory 19G \
--single HH25_RNAseq_R1.fastq --CPU 6

# Then can run on shared or else

#!/bin/sh

#SBATCH --time=12:00:00
#SBATCH --cpus-per-task=20
#SBATCH --mem=40G
#SBATCH --partition=shared
#SBATCH --mail-type=ALL


module load GCC/6.3.0-2.27 OpenMPI/2.0.2 Trinity/2.6.6 Salmon/0.9.1-Python-2.7.$

srun Trinity --seqType fq --max_memory 39G \
         --single HH25_RNAseq_R1.fastq --CPU 20

# saved: runjob.sh

#####
# submit SBATCH file to Baobab
#####

sbatch runjob.sh

#slurm-8999494.out

sacct --format=Start,Elapsed,AveCPU,State,MaxRSS,JobID,NodeList,ReqMem --units=G -j 8999494

#      Start    Elapsed     AveCPU      State     MaxRSS        JobID        NodeList     ReqMem 
#------------------- ---------- ---------- ---------- ---------- ------------ --------------- ---------- 
#2018-07-20T13:20:08   09:54:56             COMPLETED            8999494              node173       40Gn 
#2018-07-20T13:20:08   09:54:56   00:00:00  COMPLETED      0.01G 8999494.bat+         node173       40Gn 
#2018-07-20T13:20:11   09:54:53   00:01:36  COMPLETED     32.03G 8999494.0            node173       40Gn 
